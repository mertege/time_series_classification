{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Spectrograms_CI4R_Datasets_77GHz_Multi_Class_LSTM_with_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mertege/time_series_classification/blob/main/3_Spectrograms_CI4R_Datasets_77GHz_Multi_Class_LSTM_with_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN4ixvH39HW6"
      },
      "source": [
        "# Burada CI4R dataseti ile Multi Class Classification yapıldı.\n",
        "# Sadece 77GHz train ve test edildi.\n",
        "# Bidirectional(GRU) ve Bidirectional(LSTM) ile paralel olarak koşuyor ve ayrı ayrı attention yapılıyor. Sonrasında concat ile birleştiliyor. \n",
        "# Çözünürlük 216x216\n",
        "# Mean test accuracy is 0.858, max test accuracy is 0.863,\n",
        "# Min test accuracy is 0.855,  std of test accuracy is 0.003.\n",
        "# Time elapsed through all process: 1799.72 sec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzJwN6GfkN8Z"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv1D,Activation, Dropout, Flatten, Dense, BatchNormalization, Normalization, Input, Conv2D, MaxPooling2D, Concatenate, GRU, LSTM, TimeDistributed, Bidirectional, ReLU\n",
        "import tensorflow as tf\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from numpy.random import seed\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import time\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from keras.callbacks import EarlyStopping\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras import backend as K \n",
        "import gc\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FERVnWrkrwE",
        "outputId": "abaab86d-3ec8-43aa-f967-970afd4f022c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o19JHieQ81cS"
      },
      "source": [
        "# 77 GHz\n",
        "bending_77GHz                 = np.load('/content/drive/MyDrive/bending_77Ghz.npy')\n",
        "bending_77GHz = np.float32(bending_77GHz)\n",
        "label_bending_77GHz           = np.zeros((bending_77GHz.shape[0],1))\n",
        "label_bending_77GHz[:]        = 1\n",
        "crawling_77GHz                = np.load('/content/drive/MyDrive/crawling_77Ghz.npy')\n",
        "crawling_77GHz = np.float32(crawling_77GHz)\n",
        "label_crawling_77GHz          = np.zeros((crawling_77GHz.shape[0],1))\n",
        "label_crawling_77GHz[:]       = 2\n",
        "kneeling_77GHz                = np.load('/content/drive/MyDrive/kneeling_77Ghz.npy')\n",
        "kneeling_77GHz = np.float32(kneeling_77GHz)\n",
        "label_kneeling_77GHz          = np.zeros((kneeling_77GHz.shape[0],1))\n",
        "label_kneeling_77GHz[:]       = 3\n",
        "limping_with_RL_Stiff_77GHz   = np.load('/content/drive/MyDrive/limping_with_RL_Stiff_77Ghz.npy')\n",
        "limping_with_RL_Stiff_77GHz = np.float32(limping_with_RL_Stiff_77GHz)\n",
        "label_limping_with_RL_Stiff_77GHz           = np.zeros((limping_with_RL_Stiff_77GHz.shape[0],1))\n",
        "label_limping_with_RL_Stiff_77GHz[:]        = 4\n",
        "picking_up_an_object_77GHz    = np.load('/content/drive/MyDrive/picking_up_an_object_77Ghz.npy')\n",
        "picking_up_an_object_77GHz = np.float32(picking_up_an_object_77GHz)\n",
        "label_picking_up_an_object_77GHz          = np.zeros((picking_up_an_object_77GHz.shape[0],1))\n",
        "label_picking_up_an_object_77GHz[:]       = 5\n",
        "scissors_gait_77GHz           = np.load('/content/drive/MyDrive/scissors_gait_77Ghz.npy')\n",
        "scissors_gait_77GHz = np.float32(scissors_gait_77GHz)\n",
        "label_scissors_gait_77GHz          = np.zeros((scissors_gait_77GHz.shape[0],1))\n",
        "label_scissors_gait_77GHz[:]       = 6\n",
        "short_steps_77GHz             = np.load('/content/drive/MyDrive/short_steps_77Ghz.npy')\n",
        "short_steps_77GHz = np.float32(short_steps_77GHz)\n",
        "label_short_steps_77GHz          = np.zeros((short_steps_77GHz.shape[0],1))\n",
        "label_short_steps_77GHz[:]       = 7\n",
        "sitting_77GHz                 = np.load('/content/drive/MyDrive/sitting_77Ghz.npy')\n",
        "sitting_77GHz = np.float32(sitting_77GHz)\n",
        "label_sitting_77GHz          = np.zeros((sitting_77GHz.shape[0],1))\n",
        "label_sitting_77GHz[:]       = 8\n",
        "walking_away_from_Radar_77GHz = np.load('/content/drive/MyDrive/walking_away_from_Radar_77Ghz.npy')\n",
        "walking_away_from_Radar_77GHz = np.float32(walking_away_from_Radar_77GHz)\n",
        "label_walking_away_from_Radar_77GHz         = np.zeros((walking_away_from_Radar_77GHz.shape[0],1))\n",
        "label_walking_away_from_Radar_77GHz[:]       = 9\n",
        "Walking_on_both_toes_77GHz    = np.load('/content/drive/MyDrive/Walking_on_both_toes_77Ghz.npy')\n",
        "Walking_on_both_toes_77GHz = np.float32(Walking_on_both_toes_77GHz)\n",
        "label_Walking_on_both_toes_77GHz         = np.zeros((Walking_on_both_toes_77GHz.shape[0],1))\n",
        "label_Walking_on_both_toes_77GHz[:]       = 10\n",
        "Walking_towards_radar_77GHz   = np.load('/content/drive/MyDrive/Walking_towards_radar_77Ghz.npy')\n",
        "Walking_towards_radar_77GHz = np.float32(Walking_towards_radar_77GHz)\n",
        "label_Walking_towards_radar_77GHz          = np.zeros((Walking_towards_radar_77GHz.shape[0],1))\n",
        "label_Walking_towards_radar_77GHz[:]       = 11\n",
        "# # 24 GHz\n",
        "# bending_24GHz                 = np.load('/content/drive/MyDrive/bending_24GHz.npy')\n",
        "# label_bending_24GHz           = np.zeros((bending_24GHz.shape[0],1))\n",
        "# label_bending_24GHz[:]        = 1\n",
        "# crawling_24GHz                = np.load('/content/drive/MyDrive/crawling_24GHz.npy')\n",
        "# label_crawling_24GHz          = np.zeros((crawling_24GHz.shape[0],1))\n",
        "# label_crawling_24GHz[:]       = 2\n",
        "# kneeling_24GHz                = np.load('/content/drive/MyDrive/kneeling_24GHz.npy')\n",
        "# label_kneeling_24GHz          = np.zeros((kneeling_24GHz.shape[0],1))\n",
        "# label_kneeling_24GHz[:]       = 3\n",
        "# limping_with_RL_Stiff_24GHz   = np.load('/content/drive/MyDrive/limping with right stiff_24GHz.npy')\n",
        "# label_limping_with_RL_Stiff_24GHz           = np.zeros((limping_with_RL_Stiff_24GHz.shape[0],1))\n",
        "# label_limping_with_RL_Stiff_24GHz[:]        = 4\n",
        "# picking_up_an_object_24GHz    = np.load('/content/drive/MyDrive/picking up object_24GHz.npy')\n",
        "# label_picking_up_an_object_24GHz          = np.zeros((picking_up_an_object_24GHz.shape[0],1))\n",
        "# label_picking_up_an_object_24GHz[:]       = 5\n",
        "# scissors_gait_24GHz           = np.load('/content/drive/MyDrive/scissors gait_24GHz.npy')\n",
        "# label_scissors_gait_24GHz          = np.zeros((scissors_gait_24GHz.shape[0],1))\n",
        "# label_scissors_gait_24GHz[:]       = 6\n",
        "# short_steps_24GHz             = np.load('/content/drive/MyDrive/short steps_24GHz.npy')\n",
        "# label_short_steps_24GHz          = np.zeros((short_steps_24GHz.shape[0],1))\n",
        "# label_short_steps_24GHz[:]       = 7\n",
        "# sitting_24GHz                 = np.load('/content/drive/MyDrive/sitting_24GHz.npy')\n",
        "# label_sitting_24GHz          = np.zeros((sitting_24GHz.shape[0],1))\n",
        "# label_sitting_24GHz[:]       = 8\n",
        "# walking_away_from_Radar_24GHz = np.load('/content/drive/MyDrive/walking away from radar_24GHz.npy')\n",
        "# label_walking_away_from_Radar_24GHz         = np.zeros((walking_away_from_Radar_24GHz.shape[0],1))\n",
        "# label_walking_away_from_Radar_24GHz[:]       = 9\n",
        "# Walking_on_both_toes_24GHz    = np.load('/content/drive/MyDrive/walking on toes both_24GHz.npy')\n",
        "# label_Walking_on_both_toes_24GHz         = np.zeros((Walking_on_both_toes_24GHz.shape[0],1))\n",
        "# label_Walking_on_both_toes_24GHz[:]       = 10\n",
        "# Walking_towards_radar_24GHz   = np.load('/content/drive/MyDrive/walking towards radar_24GHz.npy')\n",
        "# label_Walking_towards_radar_24GHz          = np.zeros((Walking_towards_radar_24GHz.shape[0],1))\n",
        "# label_Walking_towards_radar_24GHz[:]       = 11\n",
        "# # Xethru\n",
        "# bending_Xethru                 = np.load('/content/drive/MyDrive/bending_Xethru.npy')\n",
        "# label_bending_Xethru           = np.zeros((bending_Xethru.shape[0],1))\n",
        "# label_bending_Xethru[:]        = 1\n",
        "# crawling_Xethru                = np.load('/content/drive/MyDrive/crawling_Xethru.npy')\n",
        "# label_crawling_Xethru          = np.zeros((crawling_Xethru.shape[0],1))\n",
        "# label_crawling_Xethru[:]       = 2\n",
        "# kneeling_Xethru                = np.load('/content/drive/MyDrive/kneeling_Xethru.npy')\n",
        "# label_kneeling_Xethru          = np.zeros((kneeling_Xethru.shape[0],1))\n",
        "# label_kneeling_Xethru[:]       = 3\n",
        "# limping_with_RL_Stiff_Xethru   = np.load('/content/drive/MyDrive/limping with right leg stiff_Xethru.npy')\n",
        "# label_limping_with_RL_Stiff_Xethru           = np.zeros((limping_with_RL_Stiff_Xethru.shape[0],1))\n",
        "# label_limping_with_RL_Stiff_Xethru[:]        = 4\n",
        "# picking_up_an_object_Xethru    = np.load('/content/drive/MyDrive/ picking up an object_Xethru.npy')\n",
        "# label_picking_up_an_object_Xethru          = np.zeros((picking_up_an_object_Xethru.shape[0],1))\n",
        "# label_picking_up_an_object_Xethru[:]       = 5\n",
        "# scissors_gait_Xethru           = np.load('/content/drive/MyDrive/scissor Gait_Xethru.npy')\n",
        "# label_scissors_gait_Xethru          = np.zeros((scissors_gait_Xethru.shape[0],1))\n",
        "# label_scissors_gait_Xethru[:]       = 6\n",
        "# short_steps_Xethru             = np.load('/content/drive/MyDrive/short Step_Xethru.npy')\n",
        "# label_short_steps_Xethru          = np.zeros((short_steps_Xethru.shape[0],1))\n",
        "# label_short_steps_Xethru[:]       = 7\n",
        "# sitting_Xethru                 = np.load('/content/drive/MyDrive/sitting_Xethru.npy')\n",
        "# label_sitting_Xethru          = np.zeros((sitting_Xethru.shape[0],1))\n",
        "# label_sitting_Xethru[:]       = 8\n",
        "# walking_away_from_Radar_Xethru = np.load('/content/drive/MyDrive/Walking away from radar_Xethru.npy')\n",
        "# label_walking_away_from_Radar_Xethru         = np.zeros((walking_away_from_Radar_Xethru.shape[0],1))\n",
        "# label_walking_away_from_Radar_Xethru[:]       = 9\n",
        "# Walking_on_both_toes_Xethru    = np.load('/content/drive/MyDrive/walking on both toes_Xethru.npy')\n",
        "# label_Walking_on_both_toes_Xethru         = np.zeros((Walking_on_both_toes_Xethru.shape[0],1))\n",
        "# label_Walking_on_both_toes_Xethru[:]       = 10\n",
        "# Walking_towards_radar_Xethru   = np.load('/content/drive/MyDrive/Walking towards the radar_Xethru.npy')\n",
        "# label_Walking_towards_radar_Xethru          = np.zeros((Walking_towards_radar_Xethru.shape[0],1))\n",
        "# label_Walking_towards_radar_Xethru[:]       = 11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fchoRm_5UtO2"
      },
      "source": [
        "label_concat = label_bending_77GHz\n",
        "del label_bending_77GHz\n",
        "label_concat = np.concatenate((label_concat,label_crawling_77GHz),axis=0)  \n",
        "del label_crawling_77GHz\n",
        "label_concat = np.concatenate((label_concat,label_kneeling_77GHz),axis=0)  \n",
        "del label_kneeling_77GHz\n",
        "label_concat = np.concatenate((label_concat,label_limping_with_RL_Stiff_77GHz),axis=0)  \n",
        "del label_limping_with_RL_Stiff_77GHz\n",
        "label_concat = np.concatenate((label_concat,label_picking_up_an_object_77GHz),axis=0)  \n",
        "del label_picking_up_an_object_77GHz\n",
        "label_concat = np.concatenate((label_concat,label_scissors_gait_77GHz),axis=0)  \n",
        "del label_scissors_gait_77GHz\n",
        "label_concat = np.concatenate((label_concat,label_short_steps_77GHz),axis=0)  \n",
        "del label_short_steps_77GHz\n",
        "label_concat = np.concatenate((label_concat,label_sitting_77GHz),axis=0)  \n",
        "del label_sitting_77GHz\n",
        "label_concat = np.concatenate((label_concat,label_walking_away_from_Radar_77GHz),axis=0)  \n",
        "del label_walking_away_from_Radar_77GHz\n",
        "label_concat = np.concatenate((label_concat,label_Walking_on_both_toes_77GHz),axis=0)  \n",
        "del label_Walking_on_both_toes_77GHz\n",
        "label_concat = np.concatenate((label_concat,label_Walking_towards_radar_77GHz),axis=0)  \n",
        "del label_Walking_towards_radar_77GHz\n",
        "\n",
        "# label_concat = label_bending_24GHz\n",
        "# del label_bending_24GHz\n",
        "# label_concat = np.concatenate((label_concat,label_crawling_24GHz),axis=0)  \n",
        "# del label_crawling_24GHz\n",
        "# label_concat = np.concatenate((label_concat,label_kneeling_24GHz),axis=0)  \n",
        "# del label_kneeling_24GHz\n",
        "# label_concat = np.concatenate((label_concat,label_limping_with_RL_Stiff_24GHz),axis=0)  \n",
        "# del label_limping_with_RL_Stiff_24GHz\n",
        "# label_concat = np.concatenate((label_concat,label_picking_up_an_object_24GHz),axis=0)  \n",
        "# del label_picking_up_an_object_24GHz\n",
        "# label_concat = np.concatenate((label_concat,label_scissors_gait_24GHz),axis=0)  \n",
        "# del label_scissors_gait_24GHz\n",
        "# label_concat = np.concatenate((label_concat,label_short_steps_24GHz),axis=0)  \n",
        "# del label_short_steps_24GHz\n",
        "# label_concat = np.concatenate((label_concat,label_sitting_24GHz),axis=0)  \n",
        "# del label_sitting_24GHz\n",
        "# label_concat = np.concatenate((label_concat,label_walking_away_from_Radar_24GHz),axis=0)  \n",
        "# del label_walking_away_from_Radar_24GHz\n",
        "# label_concat = np.concatenate((label_concat,label_Walking_on_both_toes_24GHz),axis=0)  \n",
        "# del label_Walking_on_both_toes_24GHz\n",
        "# label_concat = np.concatenate((label_concat,label_Walking_towards_radar_24GHz),axis=0)  \n",
        "# del label_Walking_towards_radar_24GHz\n",
        "\n",
        "\n",
        "# label_concat = label_bending_Xethru\n",
        "# del label_bending_Xethru\n",
        "# label_concat = np.concatenate((label_concat,label_crawling_Xethru),axis=0)  \n",
        "# del label_crawling_Xethru\n",
        "# label_concat = np.concatenate((label_concat,label_kneeling_Xethru),axis=0)  \n",
        "# del label_kneeling_Xethru\n",
        "# label_concat = np.concatenate((label_concat,label_limping_with_RL_Stiff_Xethru),axis=0)  \n",
        "# del label_limping_with_RL_Stiff_Xethru\n",
        "# label_concat = np.concatenate((label_concat,label_picking_up_an_object_Xethru),axis=0)  \n",
        "# del label_picking_up_an_object_Xethru\n",
        "# label_concat = np.concatenate((label_concat,label_scissors_gait_Xethru),axis=0)  \n",
        "# del label_scissors_gait_Xethru\n",
        "# label_concat = np.concatenate((label_concat,label_short_steps_Xethru),axis=0)  \n",
        "# del label_short_steps_Xethru\n",
        "# label_concat = np.concatenate((label_concat,label_sitting_Xethru),axis=0)  \n",
        "# del label_sitting_Xethru\n",
        "# label_concat = np.concatenate((label_concat,label_walking_away_from_Radar_Xethru),axis=0)  \n",
        "# del label_walking_away_from_Radar_Xethru\n",
        "# label_concat = np.concatenate((label_concat,label_Walking_on_both_toes_Xethru),axis=0)  \n",
        "# del label_Walking_on_both_toes_Xethru\n",
        "# label_concat = np.concatenate((label_concat,label_Walking_towards_radar_Xethru),axis=0)  \n",
        "# del label_Walking_towards_radar_Xethru"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_upOlnklMNhD"
      },
      "source": [
        "# 77 GHz\n",
        "spectrogram_77GHz_concat = np.concatenate((bending_77GHz,crawling_77GHz),axis=0)\n",
        "del bending_77GHz\n",
        "del crawling_77GHz\n",
        "spectrogram_77GHz_concat = np.concatenate((spectrogram_77GHz_concat,kneeling_77GHz               ),axis=0)\n",
        "del kneeling_77GHz\n",
        "spectrogram_77GHz_concat = np.concatenate((spectrogram_77GHz_concat,limping_with_RL_Stiff_77GHz  ),axis=0)\n",
        "del limping_with_RL_Stiff_77GHz\n",
        "spectrogram_77GHz_concat = np.concatenate((spectrogram_77GHz_concat,picking_up_an_object_77GHz   ),axis=0)\n",
        "del picking_up_an_object_77GHz\n",
        "spectrogram_77GHz_concat = np.concatenate((spectrogram_77GHz_concat,scissors_gait_77GHz          ),axis=0)\n",
        "del scissors_gait_77GHz\n",
        "spectrogram_77GHz_concat = np.concatenate((spectrogram_77GHz_concat,short_steps_77GHz            ),axis=0)\n",
        "del short_steps_77GHz\n",
        "spectrogram_77GHz_concat = np.concatenate((spectrogram_77GHz_concat,sitting_77GHz                ),axis=0)\n",
        "del sitting_77GHz\n",
        "spectrogram_77GHz_concat = np.concatenate((spectrogram_77GHz_concat,walking_away_from_Radar_77GHz),axis=0)\n",
        "del walking_away_from_Radar_77GHz\n",
        "spectrogram_77GHz_concat = np.concatenate((spectrogram_77GHz_concat,Walking_on_both_toes_77GHz   ),axis=0)\n",
        "del Walking_on_both_toes_77GHz\n",
        "spectrogram_77GHz_concat = np.concatenate((spectrogram_77GHz_concat,Walking_towards_radar_77GHz  ),axis=0)\n",
        "del Walking_towards_radar_77GHz\n",
        "# # 24 GHz\n",
        "# spectrogram_24GHz_concat = np.concatenate((bending_24GHz,crawling_24GHz),axis=0)\n",
        "# del bending_24GHz\n",
        "# del crawling_24GHz\n",
        "# spectrogram_24GHz_concat = np.concatenate((spectrogram_24GHz_concat,kneeling_24GHz               ),axis=0)\n",
        "# del kneeling_24GHz\n",
        "# spectrogram_24GHz_concat = np.concatenate((spectrogram_24GHz_concat,limping_with_RL_Stiff_24GHz  ),axis=0)\n",
        "# del limping_with_RL_Stiff_24GHz\n",
        "# spectrogram_24GHz_concat = np.concatenate((spectrogram_24GHz_concat,picking_up_an_object_24GHz   ),axis=0)\n",
        "# del picking_up_an_object_24GHz\n",
        "# spectrogram_24GHz_concat = np.concatenate((spectrogram_24GHz_concat,scissors_gait_24GHz          ),axis=0)\n",
        "# del scissors_gait_24GHz\n",
        "# spectrogram_24GHz_concat = np.concatenate((spectrogram_24GHz_concat,short_steps_24GHz            ),axis=0)\n",
        "# del short_steps_24GHz\n",
        "# spectrogram_24GHz_concat = np.concatenate((spectrogram_24GHz_concat,sitting_24GHz                ),axis=0)\n",
        "# del sitting_24GHz\n",
        "# spectrogram_24GHz_concat = np.concatenate((spectrogram_24GHz_concat,walking_away_from_Radar_24GHz),axis=0)\n",
        "# del walking_away_from_Radar_24GHz\n",
        "# spectrogram_24GHz_concat = np.concatenate((spectrogram_24GHz_concat,Walking_on_both_toes_24GHz   ),axis=0)\n",
        "# del Walking_on_both_toes_24GHz\n",
        "# spectrogram_24GHz_concat = np.concatenate((spectrogram_24GHz_concat,Walking_towards_radar_24GHz  ),axis=0)\n",
        "# del Walking_towards_radar_24GHz\n",
        "\n",
        "\n",
        "# # Xethru\n",
        "# spectrogram_Xethru_concat = np.concatenate((bending_Xethru,crawling_Xethru),axis=0)\n",
        "# del bending_Xethru\n",
        "# del crawling_Xethru\n",
        "# spectrogram_Xethru_concat = np.concatenate((spectrogram_Xethru_concat,kneeling_Xethru               ),axis=0)\n",
        "# del kneeling_Xethru\n",
        "# spectrogram_Xethru_concat = np.concatenate((spectrogram_Xethru_concat,limping_with_RL_Stiff_Xethru  ),axis=0)\n",
        "# del limping_with_RL_Stiff_Xethru\n",
        "# spectrogram_Xethru_concat = np.concatenate((spectrogram_Xethru_concat,picking_up_an_object_Xethru   ),axis=0)\n",
        "# del picking_up_an_object_Xethru\n",
        "# spectrogram_Xethru_concat = np.concatenate((spectrogram_Xethru_concat,scissors_gait_Xethru          ),axis=0)\n",
        "# del scissors_gait_Xethru\n",
        "# spectrogram_Xethru_concat = np.concatenate((spectrogram_Xethru_concat,short_steps_Xethru            ),axis=0)\n",
        "# del short_steps_Xethru\n",
        "# spectrogram_Xethru_concat = np.concatenate((spectrogram_Xethru_concat,sitting_Xethru                ),axis=0)\n",
        "# del sitting_Xethru\n",
        "# spectrogram_Xethru_concat = np.concatenate((spectrogram_Xethru_concat,walking_away_from_Radar_Xethru),axis=0)\n",
        "# del walking_away_from_Radar_Xethru\n",
        "# spectrogram_Xethru_concat = np.concatenate((spectrogram_Xethru_concat,Walking_on_both_toes_Xethru   ),axis=0)\n",
        "# del Walking_on_both_toes_Xethru\n",
        "# spectrogram_Xethru_concat = np.concatenate((spectrogram_Xethru_concat,Walking_towards_radar_Xethru  ),axis=0)\n",
        "# del Walking_towards_radar_Xethru\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq7lpIJPLnXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60aeb4ef-b76c-4f2a-8c71-47a33c390204"
      },
      "source": [
        "# One-Hot Encode Label\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(label_concat)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded_labels = onehot_encoder.fit_transform(integer_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFp_PErnMLN2"
      },
      "source": [
        "# Concat range-doppler data\n",
        "range_doppler_concat = spectrogram_77GHz_concat\n",
        "range_doppler_concat_label = label_concat\n",
        "# Shuffle concat range doppler\n",
        "shuffle_indx = random.sample(range(0, range_doppler_concat.shape[0]), range_doppler_concat.shape[0]) # split validation data\n",
        "range_doppler_concat_shuffle = range_doppler_concat[shuffle_indx,:,:,:]\n",
        "range_doppler_concat_label_shuffle = range_doppler_concat_label[shuffle_indx,:]\n",
        "# Concat range-doppler data\n",
        "# spectrogram_concat = spectrogram_77GHz_concat\n",
        "spectrogram_concat_label = onehot_encoded_labels\n",
        "# Shuffle concat range doppler\n",
        "# spectrogram_concat_shuffle = spectrogram_concat[shuffle_indx,:,:,:]\n",
        "spectrogram_concat_label_shuffle = spectrogram_concat_label[shuffle_indx,:]\n",
        "# Third Spectrogram\n",
        "# third_spectrogram_concat = spectrogram_77GHz_concat\n",
        "# third_spectrogram_concat_shuffle = third_spectrogram_concat[shuffle_indx,:,:,:]\n",
        "del range_doppler_concat\n",
        "del spectrogram_77GHz_concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# range_doppler_concat_shuffle_new = np.zeros((735,201,368,1))\n",
        "# for ii in range(range_doppler_concat_shuffle.shape[0]):\n",
        "#   aa = range_doppler_concat_shuffle[ii,:,:,0]\n",
        "#   range_doppler_concat_shuffle_new[ii,:,:,0] = cv2.resize(aa, (368, 201),interpolation = cv2.INTER_CUBIC)\n",
        "# range_doppler_concat_shuffle = range_doppler_concat_shuffle_new\n",
        "# del aa\n",
        "# del range_doppler_concat_shuffle_new"
      ],
      "metadata": {
        "id": "TG8i5jexgAbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1aBNkjoLCvI"
      },
      "source": [
        "# ---------------- Augmente and shuffle (train and test) data data ----------------\n",
        "def mixup_augmentation(range_doppler_training_data, labels, repeat_of_mixup, alpha, beta):\n",
        "    batch_size = range_doppler_training_data.shape[0]\n",
        "    concat_images_range_doppler = np.zeros((batch_size*(repeat_of_mixup+1),range_doppler_training_data.shape[1],range_doppler_training_data.shape[2],range_doppler_training_data.shape[3]))\n",
        "    concat_label = np.zeros((batch_size*(repeat_of_mixup+1),labels.shape[1]))\n",
        "\n",
        "    # integer_training_labels = np.argmax(labels, axis=1)\n",
        "    # np.where(integer_training_labels == 0)\n",
        "\n",
        "    if repeat_of_mixup == 0:\n",
        "      concat_images_range_doppler = range_doppler_training_data\n",
        "      concat_label = labels      \n",
        "    else:\n",
        "      for ii in range(repeat_of_mixup):\n",
        "        # shuffle train dataset\n",
        "        shuffle_indx_1 = random.sample(range(0, range_doppler_training_data.shape[0]), range_doppler_training_data.shape[0]) # split validation data\n",
        "        range_doppler_training_data_shuffled_1 = range_doppler_training_data[shuffle_indx_1,:,:,:]\n",
        "        labels_shuffled_1 = labels[shuffle_indx_1,:]\n",
        "\n",
        "        shuffle_indx_2 = random.sample(range(0, range_doppler_training_data.shape[0]), range_doppler_training_data.shape[0]) # split validation data\n",
        "        range_doppler_training_data_shuffled_2 = range_doppler_training_data[shuffle_indx_2,:,:,:]\n",
        "        labels_shuffled_2 = labels[shuffle_indx_2,:]\n",
        "\n",
        "        # shuffle_indx_3 = random.sample(range(0, range_doppler_training_data.shape[0]), range_doppler_training_data.shape[0]) # split validation data\n",
        "        # range_doppler_training_data_shuffled_3 = range_doppler_training_data[shuffle_indx_3,:,:,:]\n",
        "        # labels_shuffled_3 = labels[shuffle_indx_3,:]\n",
        "\n",
        "        # shuffle_indx_4 = random.sample(range(0, range_doppler_training_data.shape[0]), range_doppler_training_data.shape[0]) # split validation data\n",
        "        # range_doppler_training_data_shuffled_4 = range_doppler_training_data[shuffle_indx_4,:,:,:]\n",
        "        # labels_shuffled_4 = labels[shuffle_indx_4,:]\n",
        "\n",
        "        # Sample lambda and reshape it to do the mixup\n",
        "        # ll = np.random.beta(alpha, beta, (batch_size,1,1,1))\n",
        "        gaussian_mean = 0.2\n",
        "        gaussian_std = 0.02\n",
        "        ll = np.random.normal(gaussian_mean, gaussian_std, (batch_size,1,1,1))\n",
        "        x_l = np.reshape(ll, (batch_size,1,1,1))\n",
        "        y_l = np.reshape(ll, (batch_size,1))\n",
        "      \n",
        "        ll_2 = np.random.normal(gaussian_mean, gaussian_std, (batch_size,1,1,1))\n",
        "        x_l_2 = np.reshape(ll_2, (batch_size,1,1,1))\n",
        "        y_l_2 = np.reshape(ll_2, (batch_size,1))\n",
        "\n",
        "        ll_3 = np.random.normal(gaussian_mean, gaussian_std, (batch_size,1,1,1))\n",
        "        x_l_3 = np.reshape(ll_3, (batch_size,1,1,1))\n",
        "        y_l_3 = np.reshape(ll_3, (batch_size,1))\n",
        "\n",
        "        \n",
        "        # Perform mixup on both images and labels by combining a pair of images/labels\n",
        "        # images_mixup_range_doppler = range_doppler_training_data_shuffled_1 * x_l + range_doppler_training_data_shuffled_2 * x_l_2 +\\\n",
        "        # range_doppler_training_data_shuffled_3 * x_l_3 + range_doppler_training_data_shuffled_4 * (1 - x_l - x_l_2 - x_l_3)\n",
        "        # labels_mixup = labels_shuffled_1 * y_l + labels_shuffled_2 * y_l_2  + labels_shuffled_3 * y_l_3 + labels_shuffled_4 * (1 - y_l - y_l_2 - y_l_3)\n",
        "        \n",
        "        images_mixup_range_doppler = range_doppler_training_data_shuffled_1 * x_l + range_doppler_training_data_shuffled_2 * (1 - x_l)\n",
        "        labels_mixup = labels_shuffled_1 * y_l + labels_shuffled_2 * (1 - y_l)\n",
        "\n",
        "        concat_images_range_doppler[ii*batch_size:(ii+1)*batch_size,:,:,:] = images_mixup_range_doppler\n",
        "        concat_label[ii*batch_size:(ii+1)*batch_size,:] = labels_mixup\n",
        "\n",
        "      concat_images_range_doppler[repeat_of_mixup*batch_size:,:,:,:] = range_doppler_training_data\n",
        "      concat_label[repeat_of_mixup*batch_size:,:] = labels\n",
        "    return (concat_images_range_doppler, concat_label)\n",
        "def vertical_mixup_augmentation(range_doppler_training_data, labels, repeat_of_mixup, alpha, beta):\n",
        "    batch_size = range_doppler_training_data.shape[0]\n",
        "    concat_images_range_doppler = np.zeros((batch_size*(repeat_of_mixup+1),range_doppler_training_data.shape[1],range_doppler_training_data.shape[2],range_doppler_training_data.shape[3]))\n",
        "    concat_label = np.zeros((batch_size*(repeat_of_mixup+1),labels.shape[1]))\n",
        "\n",
        "    # integer_training_labels = np.argmax(labels, axis=1)\n",
        "    # np.where(integer_training_labels == 0)\n",
        "\n",
        "    if repeat_of_mixup == 0:\n",
        "      concat_images_range_doppler = range_doppler_training_data\n",
        "      concat_label = labels      \n",
        "    else:\n",
        "      for ii in range(repeat_of_mixup):\n",
        "        # shuffle train dataset\n",
        "        shuffle_indx_1 = random.sample(range(0, range_doppler_training_data.shape[0]), range_doppler_training_data.shape[0]) # split validation data\n",
        "        range_doppler_training_data_shuffled_1 = range_doppler_training_data[shuffle_indx_1,:,:,:]\n",
        "        labels_shuffled_1 = labels[shuffle_indx_1,:]\n",
        "\n",
        "        shuffle_indx_2 = random.sample(range(0, range_doppler_training_data.shape[0]), range_doppler_training_data.shape[0]) # split validation data\n",
        "        range_doppler_training_data_shuffled_2 = range_doppler_training_data[shuffle_indx_2,:,:,:]\n",
        "        labels_shuffled_2 = labels[shuffle_indx_2,:]\n",
        "\n",
        "        images_mixup_range_doppler = np.zeros((range_doppler_training_data.shape))\n",
        "\n",
        "        gaussian_mean = 0.2\n",
        "        gaussian_std = 0.02\n",
        "        ll_1 = np.random.normal(gaussian_mean, gaussian_std, (batch_size,1))\n",
        "        vertical_resolution = range_doppler_training_data_shuffled_1.shape[2]\n",
        "        index_number_1 = int(vertical_resolution*ll_1[0])\n",
        "        index_number_2 = vertical_resolution - index_number_1\n",
        "        shuffle_indx_1 = random.sample(range(0, vertical_resolution), index_number_1) # split validation data\n",
        "        shuffle_indx_2 = np.delete(range(0, vertical_resolution), shuffle_indx_1) # split training data\n",
        "\n",
        "        images_mixup_range_doppler[:,:,shuffle_indx_1,0] = range_doppler_training_data_shuffled_1[:,:,shuffle_indx_1,0]\n",
        "        images_mixup_range_doppler[:,:,shuffle_indx_2,0] = range_doppler_training_data_shuffled_2[:,:,shuffle_indx_2,0]\n",
        "        \n",
        "        # images_mixup_range_doppler = range_doppler_training_data_shuffled_1 * x_l + range_doppler_training_data_shuffled_2 * (1 - x_l)\n",
        "\n",
        "        labels_mixup = labels_shuffled_1 * ll_1 + labels_shuffled_2 * (1 - ll_1)\n",
        "\n",
        "        concat_images_range_doppler[ii*batch_size:(ii+1)*batch_size,:,:,:] = images_mixup_range_doppler\n",
        "        concat_label[ii*batch_size:(ii+1)*batch_size,:] = labels_mixup\n",
        "\n",
        "      concat_images_range_doppler[repeat_of_mixup*batch_size:,:,:,:] = range_doppler_training_data\n",
        "      concat_label[repeat_of_mixup*batch_size:,:] = labels\n",
        "    return (concat_images_range_doppler, concat_label)\n",
        "def split_and_augmentation_of_training(range_doppler_concat_shuffle_train,range_doppler_concat_label_shuffle_train,\\\n",
        "                                       repeat_of_mixup, augmentation_enable):\n",
        "  # ---------------- Parameters ----------------\n",
        "  # to split train and validation with same distribution\n",
        "  alpha = 0.1\n",
        "  beta = 5\n",
        "  dummy_label = np.zeros((range_doppler_concat_shuffle_train.shape[0],1))\n",
        "  for randomlist_for_train_indx, randomlist_for_validation_indx in kfold.split(range_doppler_concat_shuffle_train,dummy_label):   \n",
        "    randomlist_for_validation_indx\n",
        "  # size_of_validation = int(0.2*range_doppler_concat_shuffle_train.shape[0])\n",
        "  # # Split validation\n",
        "  # randomlist_for_validation_indx = random.sample(range(0, range_doppler_concat_shuffle_train.shape[0]), size_of_validation) # split validation data\n",
        "  # randomlist_for_train_indx = np.delete(range(0, range_doppler_concat_shuffle_train.shape[0]), randomlist_for_validation_indx) # split training data\n",
        "  # get validation data\n",
        "  spectrogram_validation_labels = range_doppler_concat_label_shuffle_train[randomlist_for_validation_indx,:]\n",
        "  range_doppler_validation_data = range_doppler_concat_shuffle_train[randomlist_for_validation_indx,:,:,:]\n",
        "  # get training data\n",
        "  spectrogram_training_labels = spectrogram_concat_label_shuffle_train[randomlist_for_train_indx,:]\n",
        "  range_doppler_training_data = range_doppler_concat_shuffle_train[randomlist_for_train_indx,:,:,:]\n",
        "\n",
        "  # (range_doppler_augmented_image,spectrograms_label)=\\\n",
        "  #  mixup_augmentation(range_doppler_training_data, spectrogram_training_labels, repeat_of_mixup, alpha, beta)\n",
        "\n",
        "  (range_doppler_augmented_image,spectrograms_label)=\\\n",
        "   vertical_mixup_augmentation(range_doppler_training_data, spectrogram_training_labels, repeat_of_mixup, alpha, beta)\n",
        "\n",
        "  return (range_doppler_augmented_image,spectrograms_label,\\\n",
        "     range_doppler_validation_data, spectrogram_validation_labels)\n",
        "\n",
        "\n",
        "\n",
        "def normalize_inputs(range_doppler_concat_shuffle, normalize_inputs_enable):\n",
        "  # ---------------- Normalize Inputs ----------------\n",
        "  if normalize_inputs_enable == True:\n",
        "    layer = Normalization(axis=None)\n",
        "    layer.adapt(range_doppler_concat_shuffle)\n",
        "    range_doppler_concat_shuffle = layer(range_doppler_concat_shuffle)\n",
        "  else:\n",
        "    range_doppler_concat_shuffle = range_doppler_concat_shuffle\n",
        "  return(range_doppler_concat_shuffle)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "range_doppler_concat_shuffle_new = np.zeros((range_doppler_concat_shuffle.shape[0],216,216,1))\n",
        "for ii in range(range_doppler_concat_shuffle.shape[0]):\n",
        "  aa = range_doppler_concat_shuffle[ii,:,:,0]\n",
        "  range_doppler_concat_shuffle_new[ii,:,:,0] = cv2.resize(aa, (216, 216),interpolation = cv2.INTER_CUBIC)\n",
        "range_doppler_concat_shuffle = range_doppler_concat_shuffle_new\n",
        "del aa\n",
        "del range_doppler_concat_shuffle_new"
      ],
      "metadata": {
        "id": "8xs6NIs4VvId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l7kn8DBfgBh"
      },
      "source": [
        "normalize_inputs_enable = 1\n",
        "range_doppler_concat_shuffle = normalize_inputs(range_doppler_concat_shuffle, normalize_inputs_enable)\n",
        "# spectrogram_concat_shuffle = normalize_inputs(spectrogram_concat_shuffle, normalize_inputs_enable)\n",
        "# third_spectrogram_concat_shuffle = normalize_inputs(third_spectrogram_concat_shuffle, normalize_inputs_enable)\n",
        "range_doppler_concat_shuffle = np.float32(range_doppler_concat_shuffle)\n",
        "# spectrogram_concat_shuffle = np.float32(spectrogram_concat_shuffle)\n",
        "# third_spectrogram_concat_shuffle = np.float32(third_spectrogram_concat_shuffle)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = range_doppler_concat_shuffle.shape[1]\n",
        "n_steps = range_doppler_concat_shuffle.shape[2]\n",
        "range_doppler_concat_shuffle = np.transpose(range_doppler_concat_shuffle, axes = (0,2,1,3)) \n",
        "# spectrogram_concat_shuffle = np.transpose(spectrogram_concat_shuffle, axes = (0,2,1,3)) \n",
        "# third_spectrogram_concat_shuffle = np.transpose(third_spectrogram_concat_shuffle, axes = (0,2,1,3)) "
      ],
      "metadata": {
        "id": "FJ8DgKewawvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# integer_training_labels = np.argmax(spectrogram_concat_label_shuffle_train, axis=1)\n",
        "# np.where(integer_training_labels == 1)"
      ],
      "metadata": {
        "id": "oJBq1S-NkRXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras import backend as K\n",
        "\n",
        "class attention(Layer):\n",
        "    \n",
        "    def __init__(self, return_sequences=True):\n",
        "        self.return_sequences = return_sequences\n",
        "        super(attention,self).__init__()\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        \n",
        "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
        "                               initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
        "                               initializer=\"zeros\")\n",
        "        \n",
        "        super(attention,self).build(input_shape)\n",
        "        \n",
        "    def call(self, x):\n",
        "        \n",
        "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
        "        a = K.softmax(e, axis=1)\n",
        "        # a = K.sigmoid(e)\n",
        "        output = x*a\n",
        "        \n",
        "        if self.return_sequences:\n",
        "            return output\n",
        "        \n",
        "        return K.sum(output, axis=1)"
      ],
      "metadata": {
        "id": "5G_sjtd-ynjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res"
      ],
      "metadata": {
        "id": "ZpnV7V-f1Ycf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNpkBBIadpPo",
        "cellView": "code"
      },
      "source": [
        "t = time.time()\n",
        "# ---------- Parameters ----------------\n",
        "augmentation_enable = True\n",
        "normalize_inputs_enable = True\n",
        "num_folds = 5\n",
        "kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = None) # random_state = 1 ile split run'dan run'a sabit.\n",
        "test_accuracy_per_run = []\n",
        "f1_score_per_run = []\n",
        "epoch_number = 100\n",
        "batch_size = 32\n",
        "dense_size = 128\n",
        "dropout_prob_dense = 0.4\n",
        "repeat_of_mixup = 0\n",
        "number_of_repeat = 5\n",
        "lstm_dropout_rate = 0.4\n",
        "unit_number_of_lstm = 64\n",
        "dense_unit_of_lstm_function = 256\n",
        "decoder_dense = 1024\n",
        "for repeat_run_number in range(number_of_repeat):\n",
        "  test_accuracy_per_fold = []\n",
        "  f1_score_per_fold = []\n",
        "  for train, test in kfold.split(range_doppler_concat_shuffle,range_doppler_concat_label_shuffle):   \n",
        "    gc.collect()\n",
        "    K.clear_session()\n",
        "\n",
        "    randomlist_for_test_indx = test\n",
        "    randomlist_for_train_indx = train\n",
        "    # test data\n",
        "    spectrogram_concat_label_shuffle_test = spectrogram_concat_label_shuffle[randomlist_for_test_indx,:]\n",
        "    range_doppler_concat_shuffle_test = range_doppler_concat_shuffle[randomlist_for_test_indx,:,:,:]\n",
        "    #train data\n",
        "    spectrogram_concat_label_shuffle_train = spectrogram_concat_label_shuffle[randomlist_for_train_indx,:]\n",
        "    range_doppler_concat_shuffle_train = range_doppler_concat_shuffle[randomlist_for_train_indx,:,:,:]\n",
        "    # ---------------- Split labels to equal them during augmentation for Validation ----------------\n",
        "    (range_doppler_augmented_image,spectrogram_concat_label_shuffle_concat,\\\n",
        "     validation_range_doppler, spectrogram_validation_labels)  =\\\n",
        "      split_and_augmentation_of_training(range_doppler_concat_shuffle_train,\\\n",
        "                                         spectrogram_concat_label_shuffle_train,\\\n",
        "                                         repeat_of_mixup, augmentation_enable)\n",
        "\n",
        "\n",
        "    def lstm_encoder_network_1(input_shape):\n",
        "      input = Input(shape=input_shape)\n",
        "      x = Bidirectional(LSTM(unit_number_of_lstm, return_sequences=True, dropout = 0.))(input)       \n",
        "      x = tf.transpose(x, perm=[0,2,1])\n",
        "      x = attention(return_sequences=True)(x)\n",
        "      x = tf.transpose(x, perm=[0,2,1])        \n",
        "      x = GlobalAveragePooling1D()(x)\n",
        "\n",
        "      return Model(input, x)\n",
        "\n",
        "    # def lstm_encoder_network_1_reversed(input_shape):\n",
        "    #   input = Input(shape=input_shape)\n",
        "    #   x = tf.image.flip_up_down(input)\n",
        "    #   x = (LSTM(unit_number_of_lstm, return_sequences=True, dropout = 0.))(x)       \n",
        "    #   x = tf.transpose(x, perm=[0,2,1])\n",
        "    #   x = attention(return_sequences=True)(x)\n",
        "    #   x = tf.transpose(x, perm=[0,2,1])        \n",
        "    #   x = GlobalAveragePooling1D()(x)\n",
        "\n",
        "    #   return Model(input, x)\n",
        "\n",
        "\n",
        "    def lstm_encoder_network_2(input_shape):\n",
        "      input = Input(shape=input_shape)\n",
        "      x = Bidirectional(GRU(unit_number_of_lstm, return_sequences=True, dropout = 0.))(input)\n",
        "      x = tf.transpose(x, perm=[0,2,1])\n",
        "      x = attention(return_sequences=True)(x)\n",
        "      x = tf.transpose(x, perm=[0,2,1])        \n",
        "      x = GlobalAveragePooling1D()(x)\n",
        "      return Model(input, x)\n",
        "    \n",
        "    # def lstm_encoder_network_2_reversed(input_shape):\n",
        "    #   input = Input(shape=input_shape)\n",
        "    #   x = tf.image.flip_up_down(input)\n",
        "    #   x = (GRU(unit_number_of_lstm, return_sequences=True, dropout = 0.))(x)\n",
        "    #   x = tf.transpose(x, perm=[0,2,1])\n",
        "    #   x = attention(return_sequences=True)(x)\n",
        "    #   x = tf.transpose(x, perm=[0,2,1])        \n",
        "    #   x = GlobalAveragePooling1D()(x)\n",
        "    #   return Model(input, x)\n",
        "\n",
        "    # def lstm_encoder_network_3(input_shape):\n",
        "    #   input = Input(shape=input_shape)\n",
        "    #   conv1 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(input)\n",
        "    #   conv1 = BatchNormalization()(conv1)\n",
        "    #   conv1 = ReLU()(conv1)\n",
        "    #   conv2 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
        "    #   conv2 = BatchNormalization()(conv2)\n",
        "    #   conv2 = ReLU()(conv2)\n",
        "\n",
        "    #   conv3 = Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
        "    #   conv3 = BatchNormalization()(conv3)\n",
        "    #   x = ReLU()(conv3)\n",
        "    #   x = tf.transpose(x, perm=[0,2,1])\n",
        "    #   x = attention(return_sequences=True)(x)\n",
        "    #   x = tf.transpose(x, perm=[0,2,1])        \n",
        "    #   x = GlobalAveragePooling1D()(x)\n",
        "\n",
        "    #   return Model(input, x)\n",
        "\n",
        "    def decoder_for_concat(input_shape):\n",
        "      input = Input(shape=input_shape)\n",
        "      # x = Dense(1024)(input)\n",
        "      # x = BatchNormalization()(x)\n",
        "      # x = Activation('LeakyReLU')(x)\n",
        "      # x = Dropout(0.5)(x)\n",
        "      x = Dense(64)(input)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = Activation('LeakyReLU')(x)\n",
        "      x = Dropout(0.45)(x)\n",
        "      x = Dense(11, activation=\"softmax\")(x)\n",
        "      return Model(input, x)\n",
        "\n",
        "    # def build_model(\n",
        "    #   input_shape,\n",
        "    #   head_size,\n",
        "    #   num_heads,\n",
        "    #   ff_dim,\n",
        "    #   num_transformer_blocks,\n",
        "    #   mlp_units,\n",
        "    #   dropout=0,\n",
        "    #   mlp_dropout=0,\n",
        "    # ):\n",
        "    #   inputs = Input(shape=input_shape)\n",
        "    #   x = inputs\n",
        "    #   for _ in range(num_transformer_blocks):\n",
        "    #       x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    #   x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    #   for dim in mlp_units:\n",
        "    #       x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "    #       outputs = layers.Dropout(mlp_dropout)(x)\n",
        "    #   # outputs = layers.Dense(11, activation=\"softmax\")(x)\n",
        "    #   return Model(inputs, outputs)\n",
        "\n",
        "    # input_shape = range_doppler_concat_shuffle.shape[1:3]\n",
        "\n",
        "    # model_t = build_model(\n",
        "    #     input_shape,\n",
        "    #     head_size=256,\n",
        "    #     num_heads=4,\n",
        "    #     ff_dim=4,\n",
        "    #     num_transformer_blocks=4,\n",
        "    #     mlp_units=[128],\n",
        "    #     mlp_dropout=0.4,\n",
        "    #     dropout=0.25,\n",
        "    # )\n",
        "\n",
        "    # lstm_input_t  = Input(shape=input_shape)\n",
        "    # processed_lstm_1_t  = model_t(lstm_input_t)\n",
        "\n",
        "    input_shape = range_doppler_concat_shuffle.shape[1:3]\n",
        "\n",
        "    base_network_lstm_1 = lstm_encoder_network_1(input_shape)\n",
        "    lstm_input_1  = Input(shape=input_shape)\n",
        "    processed_lstm_1  = base_network_lstm_1(lstm_input_1)\n",
        "\n",
        "\n",
        "    base_network_lstm_2 = lstm_encoder_network_2(input_shape)\n",
        "    lstm_input_2  = Input(shape=input_shape)\n",
        "    processed_lstm_2  = base_network_lstm_2(lstm_input_1)\n",
        "\n",
        "    # base_network_lstm_1_reversed = lstm_encoder_network_1_reversed(input_shape)\n",
        "    # lstm_input_1_reversed  = Input(shape=input_shape)\n",
        "    # processed_lstm_1_reversed  = base_network_lstm_1(lstm_input_1_reversed)\n",
        "\n",
        "\n",
        "    # base_network_lstm_2_reversed = lstm_encoder_network_2_reversed(input_shape)\n",
        "    # lstm_input_2_reversed  = Input(shape=input_shape)\n",
        "    # processed_lstm_2_reversed  = base_network_lstm_2(lstm_input_2_reversed)\n",
        "\n",
        "\n",
        "    # base_network_lstm_3 = lstm_encoder_network_3(input_shape)\n",
        "    # lstm_input_3  = Input(shape=input_shape)\n",
        "    # processed_lstm_3  = base_network_lstm_3(lstm_input_1)\n",
        "\n",
        "    concat_layer = Concatenate()([processed_lstm_1, processed_lstm_2])\n",
        "\n",
        "\n",
        "\n",
        "    base_decoder_network = decoder_for_concat((concat_layer.shape[1]))\n",
        "    out = base_decoder_network(concat_layer)\n",
        "\n",
        "    model = Model(inputs=[lstm_input_1], outputs=[out])\n",
        "\n",
        "    print(base_network_lstm_1.summary()) \n",
        "    print(base_network_lstm_2.summary()) \n",
        "    # print(model_t.summary()) \n",
        "    print(base_decoder_network.summary())\n",
        "    # ---------------- Compile and Fit ----------------\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    earlyStopping = EarlyStopping(monitor='val_loss', patience=30, verbose=0,restore_best_weights=True, mode='min')\n",
        "    # earlyStopping = EarlyStopping(monitor='val_accuracy', patience=15, verbose=0,restore_best_weights=True, mode='max')\n",
        "    history = model.fit((range_doppler_augmented_image),(spectrogram_concat_label_shuffle_concat),\n",
        "                    epochs=epoch_number,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle = True,\n",
        "                    callbacks=[earlyStopping],\n",
        "                    validation_data = ((validation_range_doppler) , (spectrogram_validation_labels)))\n",
        "    tf.keras.models.load_model\n",
        "    test_loss, test_accuracy  = model.evaluate([range_doppler_concat_shuffle_test],\\\n",
        "                                               [spectrogram_concat_label_shuffle_test],\n",
        "                  batch_size=batch_size)\n",
        "    # ---------------- Get Test Results ----------------\n",
        "    # y_test_predicted = model.predict((range_doppler_concat_shuffle_test,spectrogram_concat_shuffle_test,third_spectrogram_concat_shuffle_test), batch_size=batch_size)\n",
        "    # # ----- Binarize y_test_predicted values -----\n",
        "    # y_test_predicted_binary = np.zeros(y_test_predicted.shape[0])\n",
        "    # for ii in range(y_test_predicted.shape[0]):\n",
        "    #   if argmax(y_test_predicted[ii,:]) == 0:\n",
        "    #     y_test_predicted_binary[ii] = 0\n",
        "    #   elif argmax(y_test_predicted[ii,:]) == 1:\n",
        "    #     y_test_predicted_binary[ii] = 1\n",
        "    #   else:\n",
        "    #     y_test_predicted_binary[ii] = 2\n",
        "    # range_doppler_concat_label_shuffle_test1 = range_doppler_concat_label_shuffle[randomlist_for_test_indx,:]\n",
        "    # test_precision, test_recall, test_f1_score, support = precision_recall_fscore_support(range_doppler_concat_label_shuffle_test1, y_test_predicted_binary, average='macro')\n",
        "    # ----------------------------------------------------------------------------------------------------------\n",
        "    test_accuracy_per_fold.append(test_accuracy)\n",
        "    # f1_score_per_fold.append(test_f1_score)\n",
        "    del model\n",
        "  test_accuracy_per_run.append(sum(test_accuracy_per_fold)/num_folds)\n",
        "  # f1_score_per_run.append(sum(f1_score_per_fold)/num_folds)\n",
        "  print(test_accuracy_per_run)\n",
        "  # print(f1_score_per_run)\n",
        "\n",
        "print(f'Mean test accuracy is {\"{:.3f}\".format(sum(test_accuracy_per_run)/number_of_repeat)},\\\n",
        " max test accuracy is {\"{:.3f}\".format(max(test_accuracy_per_run))},\\\n",
        " min test accuracy is {\"{:.3f}\".format(min(test_accuracy_per_run))}, \\\n",
        " std of test accuracy is {\"{:.3f}\".format(np.std(test_accuracy_per_run, axis=0))}.')\n",
        "elapsed = time.time() - t\n",
        "print(f'Time elapsed through all process: {\"{:.2f}\".format(elapsed)}, sec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N7v4PDP4Dv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5d2334-a420-4df5-9aa2-4c088feb0b99"
      },
      "source": [
        "print(f'Mean test accuracy is {\"{:.3f}\".format(sum(test_accuracy_per_run)/number_of_repeat)},\\\n",
        " max test accuracy is {\"{:.3f}\".format(max(test_accuracy_per_run))},')\n",
        "print(f'Min test accuracy is {\"{:.3f}\".format(min(test_accuracy_per_run))}, \\\n",
        " std of test accuracy is {\"{:.3f}\".format(np.std(test_accuracy_per_run, axis=0))}.')\n",
        "print(f'Time elapsed through all process: {\"{:.2f}\".format(elapsed)} sec')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean test accuracy is 0.858, max test accuracy is 0.863,\n",
            "Min test accuracy is 0.855,  std of test accuracy is 0.003.\n",
            "Time elapsed through all process: 1799.72 sec\n"
          ]
        }
      ]
    }
  ]
}